{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import os\n",
    "import os.path\n",
    "import statistics as stat\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward (V, a, b, initial_distribution):\n",
    "    ## probability of being in state j at trial t, output is T*M matrix, T is number of trials, M is number of states\n",
    "    alpha = np.zeros((V.shape[0],a.shape[0]))\n",
    "    alpha[0, :] = initial_distribution * b[:, V[0]]\n",
    "    for t in range(1, V.shape[0]):\n",
    "        for j in range(a.shape[0]):\n",
    "            alpha[t, j] = alpha[t - 1].dot(a[:, j]) * b[j, V[t]]\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward (V, a, b):\n",
    "    ## time-reversed version of forward algoritms\n",
    "    ## output is T*M matrix, T is number of trials, M is number of states\n",
    "    beta = np.zeros((V.shape[0], a.shape[0]))\n",
    " \n",
    "    # setting beta(T) = 1\n",
    "    beta[V.shape[0] - 1] = np.ones((a.shape[0]))\n",
    " \n",
    "    # Loop in backward way from T-1 to\n",
    "    # Due to python indexing the actual loop will be T-2 to 0\n",
    "    for t in range(V.shape[0] - 2, -1, -1):\n",
    "        for j in range(a.shape[0]):\n",
    "            beta[t, j] = (beta[t + 1] * b[:, V[t + 1]]).dot(a[j, :])\n",
    " \n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baum_welch(V, a, b, initial_distribution, n_iter=100, parameterTying = True):\n",
    "    M = a.shape[0] ## number of states\n",
    "    T = len(V) ##  number of trials\n",
    " \n",
    "    for n in range(n_iter):\n",
    "        alpha = forward(V, a, b, initial_distribution)\n",
    "        beta = backward(V, a, b)\n",
    "        \n",
    "        ## xi = p (s(t) = i, s(t+1) = j | observation, model)\n",
    "        xi = np.zeros((M, M, T - 1))\n",
    "        for t in range(T - 1):\n",
    "            denominator = np.dot(np.dot(alpha[t, :].T, a) * b[:, V[t + 1]].T, beta[t + 1, :])\n",
    "            for i in range(M):\n",
    "                numerator = alpha[t, i] * a[i, :] * b[:, V[t + 1]].T * beta[t + 1, :].T\n",
    "                xi[i, :, t] = numerator / denominator\n",
    "\n",
    "        ## gamma = p (s(t)=i |observation, model) = sum_j^M {xi}\n",
    "        gamma = np.sum(xi, axis=1)\n",
    "        \n",
    "        transMatrixNum = np.sum(xi, 2)\n",
    "        transMatrixDem = np.sum(gamma, axis=1).reshape((-1, 1))\n",
    "        \n",
    "        ## a is the transition matrix being iteratively optmized and will eventually converge\n",
    "        a = transMatrixNum/transMatrixDem\n",
    "\n",
    "    ## tie parameter here\n",
    "    if parameterTying:\n",
    "        a[0,1] = (a[0,1] + a[0,2])/2\n",
    "        a[0,2] = a[0,1]\n",
    "\n",
    "        a[1,1] = (a[1,1]+a[2,2])/2\n",
    "        a[2,2] = a[1,1]\n",
    "\n",
    "        a[1,0] = (a[1,0]+a[2,0])/2\n",
    "        a[2,0] = a[1,0]\n",
    "    \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi(V, a, b, initial_distribution):\n",
    "    T = V.shape[0] ## number of trial\n",
    "    M = a.shape[0] ## number of states\n",
    "\n",
    "    omega = np.zeros((T, M))\n",
    "    #omega[0, :] = np.log(initial_distribution * b[:, V[0]]) # prior\n",
    "    omega[0, :] = (initial_distribution * b[:, V[0]]) # prior\n",
    "\n",
    "    prev = np.zeros((T - 1, M)) \n",
    " \n",
    "    for t in range(1, T):\n",
    "        for j in range(M):\n",
    "            # Same as Forward Probability\n",
    "            probability = omega[t - 1] + np.log(a[:, j]) + np.log(b[j, V[t]])\n",
    "            \n",
    "            # This is our most probable state given previous state at time t (1)\n",
    "            prev[t - 1, j] = np.argmax(probability)\n",
    " \n",
    "            # This is the probability of the most probable state (2)\n",
    "            omega[t, j] = np.max(probability)\n",
    "    \n",
    "\n",
    "    ## shape of omega is 300x3\n",
    " \n",
    "    # Path Array\n",
    "    S = np.zeros(T)\n",
    " \n",
    "    # Find the most probable last hidden state\n",
    "    last_state = np.argmax(omega[T - 1, :])\n",
    " \n",
    "    S[0] = last_state\n",
    "    backtrack_index = 1\n",
    "    for i in range(T - 2, -1, -1):\n",
    "        S[backtrack_index] = prev[i, int(last_state)]\n",
    "        last_state = prev[i, int(last_state)]\n",
    "        backtrack_index += 1\n",
    " \n",
    "    # Flip the path array since we were backtracking\n",
    "    result = np.flip(S, axis=0)\n",
    "    \n",
    " \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitHMM (choice):  ### the input is an array of choice, make sure choices are coded as 0 and 1\n",
    "    \n",
    "    ## emission probs (p(choice|state))\n",
    "    b = np.array([[1/2,1/2],[1,0],[0,1]])\n",
    "\n",
    "    # initial prob distribution\n",
    "    # start in exploration state\n",
    "    initial_distribution = np.array((1,0,0))\n",
    "\n",
    "    ## reseeding to find the real optimized transition matrix\n",
    "    reseed = 10\n",
    "    count = -1\n",
    "    optimizedA = []\n",
    "\n",
    "    while True:\n",
    "        count += 1\n",
    "\n",
    "        ### initialize a random transition matrix A\n",
    "        rand1 = np.random.random()\n",
    "        rand2 = np.random.random()\n",
    "        a = np.array([[(1-rand1),rand1/2,rand1/2],[1-rand2,rand2,0,],[1-rand2,0,rand2]])\n",
    "\n",
    "        ### using forward-backward algorithms (baum-welch) to find transition matrix\n",
    "        ### if examining two states (explore vs. exploit), parameterTying =True. THis default\n",
    "        ### if examining three states (biased exploitation), parameterTying = False\n",
    "        transMatrix=baum_welch(choice,a,b,initial_distribution, n_iter =100) #matrix A and B\n",
    "        \n",
    "        ## reseeding to check if this is the global minimum\n",
    "        flatMat = np.ndarray.flatten(transMatrix)\n",
    "        \n",
    "        if flatMat[0] <= 0.5 or flatMat[3] >= 0.5:\n",
    "            print ('matrix criteria not reached')\n",
    "            if count == reseed:\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            if count == 0:\n",
    "                    optimizedA.append (flatMat)\n",
    "\n",
    "            elif count == reseed:\n",
    "                print (\"break because it has reached reeding limit *********\")\n",
    "                break\n",
    "            else:\n",
    "                for m in range (len(optimizedA)):\n",
    "                    if np.allclose (flatMat, optimizedA[m], rtol=0.01, atol=0.01, equal_nan=False) == False:\n",
    "                        optimizedA.append (flatMat)  \n",
    "                    else:\n",
    "                        break   \n",
    "                    break\n",
    "                break\n",
    "\n",
    "    print (transMatrix)\n",
    "    explorePotential= transMatrix[0,0]\n",
    "    exploitPotential = transMatrix[1,1]\n",
    "\n",
    "    ## fit back to each session using viterbi algorithms\n",
    "    stateLabel = viterbi(choice,transMatrix,b,initial_distribution).tolist()\n",
    "\n",
    "    return stateLabel, explorePotential, exploitPotential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.78200881 0.1089956  0.1089956 ]\n",
      " [0.35825665 0.64174335 0.        ]\n",
      " [0.35825665 0.         0.64174335]]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 0.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 0.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "0.7820088071329018\n",
      "0.6417433457765234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4c/qtyzwxns1jz7zlm880prvytw0000gn/T/ipykernel_11158/3447853257.py:14: RuntimeWarning: divide by zero encountered in log\n",
      "  probability = omega[t - 1] + np.log(a[:, j]) + np.log(b[j, V[t]])\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/sijinchen/Desktop/HMM python/test.csv')  ## file path\n",
    "choice = df['choice'].values-1   ## make sure the choices are 0 and 1\n",
    "\n",
    "stateLabel, explorePotential, exploitPotential = fitHMM (choice)\n",
    "\n",
    "print (stateLabel)\n",
    "print(explorePotential)\n",
    "print (exploitPotential)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
